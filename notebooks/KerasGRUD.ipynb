{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b67c4a-ae74-4046-bda1-cf1fccee38eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, roc_auc_score, f1_score, roc_curve\n",
    "from transformers import BertTokenizer, BertModel, BertForSequenceClassification, AdamW\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import torch.utils.data as utils\n",
    "import matplotlib.pyplot as plt\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210f561a-0520-49ac-858f-b8899ced0d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2021 = {}\n",
    "path = 'eRisk2021_T1/data/'\n",
    "\n",
    "for fname in os.listdir(path):\n",
    "    if not fname.endswith('.xml'):\n",
    "        continue\n",
    "    file_path = os.path.join(path, fname)\n",
    "    with open(file_path, 'r') as file:\n",
    "        _id = fname[:-4]\n",
    "        data2021[_id] = {'time':[], 'text':[]}\n",
    "        for line in [x.strip() for x in file.read().split('\\n')]:\n",
    "            if line.startswith('<TEXT>'):\n",
    "                data2021[_id]['text'].append(line[6:-7])\n",
    "            elif line.startswith('<DATE>'):\n",
    "                data2021[_id]['time'].append((line[6:-7]))\n",
    "\n",
    "arr = np.loadtxt('eRisk2021_T1/risk_golden_truth.txt', delimiter=' ', dtype=object)\n",
    "for row in arr:\n",
    "  _id, isSad = row\n",
    "  data2021[_id]['isSad'] = int(isSad)\n",
    "\n",
    "data2022 = {}\n",
    "path = 'eRisk2022_T1/data/'\n",
    "\n",
    "for fname in os.listdir(path):\n",
    "    if not fname.endswith('.xml'):\n",
    "        continue\n",
    "    file_path = os.path.join(path, fname)\n",
    "    with open(file_path, 'r') as file:\n",
    "        _id = fname[:-4]\n",
    "        data2022[_id] = {'time':[], 'text':[]}\n",
    "        for line in [x.strip() for x in file.read().split('\\n')]:\n",
    "            if line.startswith('<TEXT>'):\n",
    "                data2022[_id]['text'].append(line[6:-7])\n",
    "            elif line.startswith('<DATE>'):\n",
    "                data2022[_id]['time'].append((line[6:-7]))\n",
    "arr = np.loadtxt('eRisk2022_T1/risk_golden_truth.txt', delimiter='\t', dtype=object)\n",
    "for row in arr:\n",
    "  _id, isSad = row\n",
    "  data2022[_id]['isSad'] = int(isSad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21bf8b58-9f38-48ac-b9fb-44a99cda1e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2021 = pd.DataFrame([(k, v['time'], v['text'], v['isSad']) for k, v in data2021.items()], columns=['ID', 'Timestamp', 'Text', 'Label'])\n",
    "df2022 = pd.DataFrame([(k, v['time'], v['text'], v['isSad']) for k, v in data2022.items()], columns=['ID', 'Timestamp', 'Text', 'Label'])\n",
    "df = pd.concat([df2021, df2022], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a918c7-0a9c-47a3-a130-f1e115fc2517",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_empty_lists(row):\n",
    "    if all([x == '' for x in row['Text']]):\n",
    "        return np.nan\n",
    "    else:\n",
    "        return row\n",
    "df_clean = df.apply(clean_empty_lists, axis=1).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e18ba9e-2fb5-497d-98be-264a2882677d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sorted = df_clean.sort_values('Label', ascending=False)\n",
    "# get all rows with Labels=1\n",
    "df_label_1 = df_sorted[df_sorted['Label'] == 1]\n",
    "# get the same amount of random samples from Labels=0\n",
    "num_samples = len(df_label_1)\n",
    "df_label_0 = df_sorted[df_sorted['Label'] == 0].sample(n=num_samples)\n",
    "# conctenate the two DataFrames and shuffle the rows\n",
    "df_concat = pd.concat([df_label_1, df_label_0]).sample(frac=1).reset_index(drop=True)\n",
    "df_concat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5973afbf-fe89-435a-b873-9dcd59e5cef7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "      <th>embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>subject483</td>\n",
       "      <td>[2019-12-02 03:45:11, 2020-03-27 22:35:24, 202...</td>\n",
       "      <td>[I posted asking to join it. But noting yet. I...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[[-0.046624403, 0.03369027, 0.03198913, -0.020...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>subject8468</td>\n",
       "      <td>[2020-10-23 08:47:48, 2020-11-03 12:17:25, 202...</td>\n",
       "      <td>[My friend just got a Switch and finally can j...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[[-0.049074702, -0.06591597, -0.069207065, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>subject3732</td>\n",
       "      <td>[2021-03-09 18:25:47, 2021-03-25 18:08:36, 202...</td>\n",
       "      <td>[Is anyone else investing in Lambo stonks? See...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[[0.010822672, -0.08347642, -0.036187872, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>subject2759</td>\n",
       "      <td>[2020-02-14 08:54:16, 2020-02-14 10:05:01, 202...</td>\n",
       "      <td>[Hello. Im 28 years old. Right now I'm jobless...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[[0.0015010262, -0.07187804, -0.031160373, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>subject7645</td>\n",
       "      <td>[2019-10-17 19:35:56, 2019-10-20 17:32:49, 201...</td>\n",
       "      <td>[Clever! ;-), They don't call it a [bully pulp...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[[0.020647164, -0.038092427, -0.0014518382, 0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            ID                                          Timestamp  \\\n",
       "0   subject483  [2019-12-02 03:45:11, 2020-03-27 22:35:24, 202...   \n",
       "1  subject8468  [2020-10-23 08:47:48, 2020-11-03 12:17:25, 202...   \n",
       "2  subject3732  [2021-03-09 18:25:47, 2021-03-25 18:08:36, 202...   \n",
       "3  subject2759  [2020-02-14 08:54:16, 2020-02-14 10:05:01, 202...   \n",
       "4  subject7645  [2019-10-17 19:35:56, 2019-10-20 17:32:49, 201...   \n",
       "\n",
       "                                                Text  Label  \\\n",
       "0  [I posted asking to join it. But noting yet. I...    1.0   \n",
       "1  [My friend just got a Switch and finally can j...    0.0   \n",
       "2  [Is anyone else investing in Lambo stonks? See...    0.0   \n",
       "3  [Hello. Im 28 years old. Right now I'm jobless...    1.0   \n",
       "4  [Clever! ;-), They don't call it a [bully pulp...    0.0   \n",
       "\n",
       "                                          embeddings  \n",
       "0  [[-0.046624403, 0.03369027, 0.03198913, -0.020...  \n",
       "1  [[-0.049074702, -0.06591597, -0.069207065, 0.0...  \n",
       "2  [[0.010822672, -0.08347642, -0.036187872, -0.0...  \n",
       "3  [[0.0015010262, -0.07187804, -0.031160373, 0.0...  \n",
       "4  [[0.020647164, -0.038092427, -0.0014518382, 0....  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Iterate over each row of the DataFrame\n",
    "for index, row in df_concat.iterrows():\n",
    "    # Get the list of timestamps and the list of text for this row\n",
    "    timestamps = row['Timestamp']\n",
    "    text_list = row['Text']\n",
    "    cleaned_text_list = [text for text in text_list if text != '']\n",
    "    if len(cleaned_text_list) == 0:\n",
    "        continue\n",
    "    cleaned_timestamps = [timestamps[i] for i in range(len(text_list)) if text_list[i] != '']\n",
    "    df_concat.at[index, 'Text'] = cleaned_text_list\n",
    "    df_concat.at[index, 'Timestamp'] = cleaned_timestamps\n",
    "    \n",
    "df_concat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ad2b1646-c13b-487a-86ce-7a18b22e7c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow\n",
    "# import tensorflow_hub as hub\n",
    "# # Load the pre-trained model\n",
    "# embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")\n",
    "# df_concat['embeddings'] = 0\n",
    "# huge_emb_lst = []\n",
    "# for i in range(len(df_concat)):\n",
    "#     emb_lst = []\n",
    "#     for text_piece in df_concat['Text'].iloc[i]:\n",
    "#         if text_piece != '':\n",
    "#             embedd = embed([str(text_piece)])\n",
    "#             embedd = np.squeeze(embedd.numpy())\n",
    "#         else:\n",
    "#             embedd = np.zeros(512)\n",
    "#         emb_lst.append(embedd)\n",
    "#     # df_concat['embeddings'].iloc[i] = emb_lst\n",
    "#     huge_emb_lst.append(emb_lst)\n",
    "# df_concat['embeddings'] = huge_emb_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0baf139d-d343-4021-b135-6c7f7695eb8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68575906-41ee-45bc-a887-2881ec8acf59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "# Generate BERT embeddings for each text in the dataset\n",
    "\n",
    "df_concat['embeddings_bert'] = 0\n",
    "huge_emb_lst = []\n",
    "for i in range(336, len(df_concat)):\n",
    "    emb_lst = []\n",
    "    for text_piece in df_concat['Text'].iloc[i]:\n",
    "        embedd = tokenizer(text_piece, padding=True, truncation=True, return_tensors='pt', max_length=512)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**embedd)\n",
    "        embeddings = outputs.last_hidden_state.mean(dim=1).cpu().numpy()\n",
    "        emb_lst.append(embeddings)\n",
    "    # df_concat['embeddings'].iloc[i] = emb_lst\n",
    "    huge_emb_lst.append(emb_lst)\n",
    "df_concat['embeddings_bert'] = huge_emb_lst\n",
    "df_concat.to_csv('df_concat.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e852a8-4e04-4662-98e1-ccf313def631",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>ID</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "      <th>embeddings_bert</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>subject9354</td>\n",
       "      <td>['2020-10-04 18:02:39', '2020-10-07 15:46:24',...</td>\n",
       "      <td>['me 2.', 'same thing, no double dipping.', 'I...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[array([[-2.27833837e-01, -3.56629044e-01, -9....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>subject6720</td>\n",
       "      <td>['2018-11-12 16:55:23', '2018-11-13 07:17:56',...</td>\n",
       "      <td>[\"[https://www.twitch.tv/videos/334960643](htt...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[array([[ 3.61625291e-02, -2.95236349e-01,  1....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>subject1939</td>\n",
       "      <td>['2017-05-03 16:49:50', '2017-05-03 22:06:28',...</td>\n",
       "      <td>[\"I just lost all of my money gambling and thi...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[array([[ 1.22508835e-02, -1.09029643e-01,  2....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>subject7835</td>\n",
       "      <td>['2017-12-29 20:00:16', '2017-12-29 23:54:22',...</td>\n",
       "      <td>['Seeking experienced voice actors to particip...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[array([[-3.89923854e-03, -2.23664463e-01,  4....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>subject2804</td>\n",
       "      <td>['2019-03-09 16:33:46', '2019-11-26 04:57:58',...</td>\n",
       "      <td>['Absolutly', '8', 'Hot!', 'Cute!', 'Very cute...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[array([[-5.30905664e-01, -3.51056904e-01, -1....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>485</td>\n",
       "      <td>subject6517</td>\n",
       "      <td>['2021-11-10 15:33:32', '2021-11-10 15:34:13',...</td>\n",
       "      <td>['Have you got rock bottom? Do you want to qui...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[array([[ 2.34189004e-01, -3.63695145e-01, -5....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>486</td>\n",
       "      <td>subject8492</td>\n",
       "      <td>['2020-08-04 21:42:26', '2020-11-24 20:20:19',...</td>\n",
       "      <td>['Ive missed well over 2 months. There is no p...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[array([[ 2.21290961e-02, -1.10986859e-01,  4....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>487</td>\n",
       "      <td>subject5487</td>\n",
       "      <td>['2021-12-20 15:27:03', '2021-12-20 16:10:38',...</td>\n",
       "      <td>[\"Hello there, I am a former JW that served as...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[array([[ 2.86593795e-01, -5.11154626e-03,  1....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>488</td>\n",
       "      <td>subject4802</td>\n",
       "      <td>['2020-02-04 20:19:32', '2020-02-04 20:54:40',...</td>\n",
       "      <td>['Im feeling absolutely helpless right now, no...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[array([[ 8.15021992e-03,  2.23562643e-01,  4....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>489</td>\n",
       "      <td>subject5834</td>\n",
       "      <td>['2021-10-12 03:37:41', '2021-10-15 18:14:29',...</td>\n",
       "      <td>['Can you share your store link so that I can ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[array([[ 8.37173685e-02, -2.89680451e-01,  2....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>490 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0           ID  \\\n",
       "0             0  subject9354   \n",
       "1             1  subject6720   \n",
       "2             2  subject1939   \n",
       "3             3  subject7835   \n",
       "4             4  subject2804   \n",
       "..          ...          ...   \n",
       "485         485  subject6517   \n",
       "486         486  subject8492   \n",
       "487         487  subject5487   \n",
       "488         488  subject4802   \n",
       "489         489  subject5834   \n",
       "\n",
       "                                             Timestamp  \\\n",
       "0    ['2020-10-04 18:02:39', '2020-10-07 15:46:24',...   \n",
       "1    ['2018-11-12 16:55:23', '2018-11-13 07:17:56',...   \n",
       "2    ['2017-05-03 16:49:50', '2017-05-03 22:06:28',...   \n",
       "3    ['2017-12-29 20:00:16', '2017-12-29 23:54:22',...   \n",
       "4    ['2019-03-09 16:33:46', '2019-11-26 04:57:58',...   \n",
       "..                                                 ...   \n",
       "485  ['2021-11-10 15:33:32', '2021-11-10 15:34:13',...   \n",
       "486  ['2020-08-04 21:42:26', '2020-11-24 20:20:19',...   \n",
       "487  ['2021-12-20 15:27:03', '2021-12-20 16:10:38',...   \n",
       "488  ['2020-02-04 20:19:32', '2020-02-04 20:54:40',...   \n",
       "489  ['2021-10-12 03:37:41', '2021-10-15 18:14:29',...   \n",
       "\n",
       "                                                  Text  Label  \\\n",
       "0    ['me 2.', 'same thing, no double dipping.', 'I...    0.0   \n",
       "1    [\"[https://www.twitch.tv/videos/334960643](htt...    0.0   \n",
       "2    [\"I just lost all of my money gambling and thi...    1.0   \n",
       "3    ['Seeking experienced voice actors to particip...    0.0   \n",
       "4    ['Absolutly', '8', 'Hot!', 'Cute!', 'Very cute...    0.0   \n",
       "..                                                 ...    ...   \n",
       "485  ['Have you got rock bottom? Do you want to qui...    1.0   \n",
       "486  ['Ive missed well over 2 months. There is no p...    0.0   \n",
       "487  [\"Hello there, I am a former JW that served as...    0.0   \n",
       "488  ['Im feeling absolutely helpless right now, no...    1.0   \n",
       "489  ['Can you share your store link so that I can ...    0.0   \n",
       "\n",
       "                                       embeddings_bert  \n",
       "0    [array([[-2.27833837e-01, -3.56629044e-01, -9....  \n",
       "1    [array([[ 3.61625291e-02, -2.95236349e-01,  1....  \n",
       "2    [array([[ 1.22508835e-02, -1.09029643e-01,  2....  \n",
       "3    [array([[-3.89923854e-03, -2.23664463e-01,  4....  \n",
       "4    [array([[-5.30905664e-01, -3.51056904e-01, -1....  \n",
       "..                                                 ...  \n",
       "485  [array([[ 2.34189004e-01, -3.63695145e-01, -5....  \n",
       "486  [array([[ 2.21290961e-02, -1.10986859e-01,  4....  \n",
       "487  [array([[ 2.86593795e-01, -5.11154626e-03,  1....  \n",
       "488  [array([[ 8.15021992e-03,  2.23562643e-01,  4....  \n",
       "489  [array([[ 8.37173685e-02, -2.89680451e-01,  2....  \n",
       "\n",
       "[490 rows x 6 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7a5b38ce-ef17-45ea-9916-8f2803aeca0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concat = pd.read_csv('df_concat.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "29cff415-5e34-48b7-acf9-620d48a56416",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "import tensorflow_hub as hub\n",
    "# Load the pre-trained model\n",
    "embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")\n",
    "df_concat['embeddings_use'] = 0\n",
    "huge_emb_lst = []\n",
    "for i in range(len(df_concat)):\n",
    "    emb_lst = []\n",
    "    for text_piece in eval(df_concat['Text'].iloc[i]):\n",
    "        if text_piece != '':\n",
    "            embedd = embed([str(text_piece)])\n",
    "            embedd = np.squeeze(embedd.numpy())\n",
    "        else:\n",
    "            embedd = np.zeros(512)\n",
    "        emb_lst.append(embedd)\n",
    "    # df_concat['embeddings'].iloc[i] = emb_lst\n",
    "    huge_emb_lst.append(emb_lst)\n",
    "df_concat['embeddings_use'] = huge_emb_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3cc16976-12a1-4015-944d-be505d2168aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>ID</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "      <th>embeddings_bert</th>\n",
       "      <th>embeddings_use</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>subject9354</td>\n",
       "      <td>['2020-10-04 18:02:39', '2020-10-07 15:46:24',...</td>\n",
       "      <td>['me 2.', 'same thing, no double dipping.', 'I...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[array([[-2.27833837e-01, -3.56629044e-01, -9....</td>\n",
       "      <td>[[0.09742043, -0.10078834, 0.05655467, 0.03573...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>subject6720</td>\n",
       "      <td>['2018-11-12 16:55:23', '2018-11-13 07:17:56',...</td>\n",
       "      <td>[\"[https://www.twitch.tv/videos/334960643](htt...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[array([[ 3.61625291e-02, -2.95236349e-01,  1....</td>\n",
       "      <td>[[0.016732637, -0.07019263, -0.06763446, 0.022...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>subject1939</td>\n",
       "      <td>['2017-05-03 16:49:50', '2017-05-03 22:06:28',...</td>\n",
       "      <td>[\"I just lost all of my money gambling and thi...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[array([[ 1.22508835e-02, -1.09029643e-01,  2....</td>\n",
       "      <td>[[-0.041338928, -0.083965495, -0.0031749755, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>subject7835</td>\n",
       "      <td>['2017-12-29 20:00:16', '2017-12-29 23:54:22',...</td>\n",
       "      <td>['Seeking experienced voice actors to particip...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[array([[-3.89923854e-03, -2.23664463e-01,  4....</td>\n",
       "      <td>[[-0.05422537, -0.028290626, -0.0151080135, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>subject2804</td>\n",
       "      <td>['2019-03-09 16:33:46', '2019-11-26 04:57:58',...</td>\n",
       "      <td>['Absolutly', '8', 'Hot!', 'Cute!', 'Very cute...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[array([[-5.30905664e-01, -3.51056904e-01, -1....</td>\n",
       "      <td>[[-0.015544569, -0.03773666, 0.0076418677, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>485</td>\n",
       "      <td>subject6517</td>\n",
       "      <td>['2021-11-10 15:33:32', '2021-11-10 15:34:13',...</td>\n",
       "      <td>['Have you got rock bottom? Do you want to qui...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[array([[ 2.34189004e-01, -3.63695145e-01, -5....</td>\n",
       "      <td>[[-0.009765577, -0.08657441, -0.010570338, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>486</td>\n",
       "      <td>subject8492</td>\n",
       "      <td>['2020-08-04 21:42:26', '2020-11-24 20:20:19',...</td>\n",
       "      <td>['Ive missed well over 2 months. There is no p...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[array([[ 2.21290961e-02, -1.10986859e-01,  4....</td>\n",
       "      <td>[[-0.05554608, -0.098843925, -0.0073674256, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>487</td>\n",
       "      <td>subject5487</td>\n",
       "      <td>['2021-12-20 15:27:03', '2021-12-20 16:10:38',...</td>\n",
       "      <td>[\"Hello there, I am a former JW that served as...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[array([[ 2.86593795e-01, -5.11154626e-03,  1....</td>\n",
       "      <td>[[-0.002484351, -0.0827845, -0.051220387, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>488</td>\n",
       "      <td>subject4802</td>\n",
       "      <td>['2020-02-04 20:19:32', '2020-02-04 20:54:40',...</td>\n",
       "      <td>['Im feeling absolutely helpless right now, no...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[array([[ 8.15021992e-03,  2.23562643e-01,  4....</td>\n",
       "      <td>[[-0.018387843, -0.090804316, -0.010818297, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>489</td>\n",
       "      <td>subject5834</td>\n",
       "      <td>['2021-10-12 03:37:41', '2021-10-15 18:14:29',...</td>\n",
       "      <td>['Can you share your store link so that I can ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[array([[ 8.37173685e-02, -2.89680451e-01,  2....</td>\n",
       "      <td>[[0.031387918, 0.024879524, 0.016873624, -0.03...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>490 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0           ID  \\\n",
       "0             0  subject9354   \n",
       "1             1  subject6720   \n",
       "2             2  subject1939   \n",
       "3             3  subject7835   \n",
       "4             4  subject2804   \n",
       "..          ...          ...   \n",
       "485         485  subject6517   \n",
       "486         486  subject8492   \n",
       "487         487  subject5487   \n",
       "488         488  subject4802   \n",
       "489         489  subject5834   \n",
       "\n",
       "                                             Timestamp  \\\n",
       "0    ['2020-10-04 18:02:39', '2020-10-07 15:46:24',...   \n",
       "1    ['2018-11-12 16:55:23', '2018-11-13 07:17:56',...   \n",
       "2    ['2017-05-03 16:49:50', '2017-05-03 22:06:28',...   \n",
       "3    ['2017-12-29 20:00:16', '2017-12-29 23:54:22',...   \n",
       "4    ['2019-03-09 16:33:46', '2019-11-26 04:57:58',...   \n",
       "..                                                 ...   \n",
       "485  ['2021-11-10 15:33:32', '2021-11-10 15:34:13',...   \n",
       "486  ['2020-08-04 21:42:26', '2020-11-24 20:20:19',...   \n",
       "487  ['2021-12-20 15:27:03', '2021-12-20 16:10:38',...   \n",
       "488  ['2020-02-04 20:19:32', '2020-02-04 20:54:40',...   \n",
       "489  ['2021-10-12 03:37:41', '2021-10-15 18:14:29',...   \n",
       "\n",
       "                                                  Text  Label  \\\n",
       "0    ['me 2.', 'same thing, no double dipping.', 'I...    0.0   \n",
       "1    [\"[https://www.twitch.tv/videos/334960643](htt...    0.0   \n",
       "2    [\"I just lost all of my money gambling and thi...    1.0   \n",
       "3    ['Seeking experienced voice actors to particip...    0.0   \n",
       "4    ['Absolutly', '8', 'Hot!', 'Cute!', 'Very cute...    0.0   \n",
       "..                                                 ...    ...   \n",
       "485  ['Have you got rock bottom? Do you want to qui...    1.0   \n",
       "486  ['Ive missed well over 2 months. There is no p...    0.0   \n",
       "487  [\"Hello there, I am a former JW that served as...    0.0   \n",
       "488  ['Im feeling absolutely helpless right now, no...    1.0   \n",
       "489  ['Can you share your store link so that I can ...    0.0   \n",
       "\n",
       "                                       embeddings_bert  \\\n",
       "0    [array([[-2.27833837e-01, -3.56629044e-01, -9....   \n",
       "1    [array([[ 3.61625291e-02, -2.95236349e-01,  1....   \n",
       "2    [array([[ 1.22508835e-02, -1.09029643e-01,  2....   \n",
       "3    [array([[-3.89923854e-03, -2.23664463e-01,  4....   \n",
       "4    [array([[-5.30905664e-01, -3.51056904e-01, -1....   \n",
       "..                                                 ...   \n",
       "485  [array([[ 2.34189004e-01, -3.63695145e-01, -5....   \n",
       "486  [array([[ 2.21290961e-02, -1.10986859e-01,  4....   \n",
       "487  [array([[ 2.86593795e-01, -5.11154626e-03,  1....   \n",
       "488  [array([[ 8.15021992e-03,  2.23562643e-01,  4....   \n",
       "489  [array([[ 8.37173685e-02, -2.89680451e-01,  2....   \n",
       "\n",
       "                                        embeddings_use  \n",
       "0    [[0.09742043, -0.10078834, 0.05655467, 0.03573...  \n",
       "1    [[0.016732637, -0.07019263, -0.06763446, 0.022...  \n",
       "2    [[-0.041338928, -0.083965495, -0.0031749755, 0...  \n",
       "3    [[-0.05422537, -0.028290626, -0.0151080135, 0....  \n",
       "4    [[-0.015544569, -0.03773666, 0.0076418677, 0.0...  \n",
       "..                                                 ...  \n",
       "485  [[-0.009765577, -0.08657441, -0.010570338, 0.0...  \n",
       "486  [[-0.05554608, -0.098843925, -0.0073674256, -0...  \n",
       "487  [[-0.002484351, -0.0827845, -0.051220387, -0.0...  \n",
       "488  [[-0.018387843, -0.090804316, -0.010818297, -0...  \n",
       "489  [[0.031387918, 0.024879524, 0.016873624, -0.03...  \n",
       "\n",
       "[490 rows x 7 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224ce2b5-17a0-4b62-814e-9f079b86f89c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "074c9931-a331-4826-aa08-59cbef0c7ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import re\n",
    "# import numpy as np\n",
    "# big_list_of_arrays = []\n",
    "# for i in range(len(df_concat)):\n",
    "#     string = df_concat['embeddings_bert'].iloc[i]\n",
    "#     embedding_str = string.replace('\\n', '')\n",
    "#     embedding_str = embedding_str.replace('  ', ' ')\n",
    "#     embedding_str = embedding_str.replace('  ', ' ')\n",
    "#     embedding_str = embedding_str.replace('  ', ' ')\n",
    "#     embedding_str = embedding_str.replace(', dtype=float32', '')\n",
    "#     array_strings = re.findall(r'array\\(\\[(.*?)\\]\\)', embedding_str)\n",
    "#     arrays = [np.array(ast.literal_eval(s)) for s in array_strings]\n",
    "#     big_list_of_arrays.append(arrays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6625af4b-3701-4275-9837-aa6dca12bc54",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concat['embeddings_bert_converted'] = big_list_of_arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7ae1988c-1a35-48f3-bbd0-ca46ca17a96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_lst = []\n",
    "for i in range(len(df_concat)):\n",
    "    time_lst.append(ast.literal_eval(df_concat['Timestamp'].iloc[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "48eb9c66-7b2e-421a-a444-c5e71295a906",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concat['Timestamp'] = time_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0d8f9c95-0767-4cdd-85c1-bd230105e1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.load('train_data.npy')\n",
    "val_data = np.load('val_data.npy')\n",
    "test_data = np.load('test_data.npy')\n",
    "train_timestamps_padded = np.load('train_timestamps_padded.npy')\n",
    "val_timestamps_padded = np.load('val_timestamps_padded.npy')\n",
    "test_timestamps_padded = np.load('test_timestamps_padded.npy')\n",
    "train_labels = np.load('train_labels.npy')\n",
    "val_labels = np.load('val_labels.npy')\n",
    "test_labels = np.load('test_labels.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "f26fed9b-12d7-443f-8618-99f154bb7f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Embedding, GRU, Dense, Dropout, Lambda\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datetime import datetime, timedelta\n",
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
    "\n",
    "# Define the number of classes\n",
    "NUM_CLASSES = 2\n",
    "\n",
    "# Define the learning rate decay parameters\n",
    "INIT_LR = 0.001\n",
    "DECAY_FACTOR = 0.1\n",
    "DECAY_EPOCHS = 10\n",
    "\n",
    "# Define the GRU parameters\n",
    "GRU_HIDDEN_DIM = 256\n",
    "DROPOUT_RATE = 0.2\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "train_texts, val_test_texts, train_labels, val_test_labels, train_timestamps, val_test_timestamps = train_test_split(\n",
    "    df_concat['embeddings_use'].values,\n",
    "    df_concat['Label'].values,\n",
    "    df_concat['Timestamp'].values,\n",
    "    test_size=0.2,\n",
    "    random_state=420\n",
    ")\n",
    "val_texts, test_texts, val_labels, test_labels, val_timestamps, test_timestamps = train_test_split(\n",
    "    val_test_texts,\n",
    "    val_test_labels,\n",
    "    val_test_timestamps,\n",
    "    train_size=0.5,\n",
    "    random_state=420\n",
    ")\n",
    "\n",
    "MAX_SEQ_LENGTH = max(len(x) for x in train_texts[:][:])\n",
    "\n",
    "# Convert the labels to one-hot vectors\n",
    "train_labels = tf.keras.utils.to_categorical(train_labels, NUM_CLASSES)\n",
    "val_labels = tf.keras.utils.to_categorical(val_labels, NUM_CLASSES)\n",
    "test_labels = tf.keras.utils.to_categorical(test_labels, NUM_CLASSES)\n",
    "\n",
    "# Pad the sequences to the same length\n",
    "train_data = tf.keras.preprocessing.sequence.pad_sequences(train_texts, maxlen=MAX_SEQ_LENGTH, dtype='float32', padding='post', truncating='post')\n",
    "val_data = tf.keras.preprocessing.sequence.pad_sequences(val_texts, maxlen=MAX_SEQ_LENGTH, dtype='float32', padding='post', truncating='post')\n",
    "test_data = tf.keras.preprocessing.sequence.pad_sequences(test_texts, maxlen=MAX_SEQ_LENGTH, dtype='float32', padding='post', truncating='post')\n",
    "\n",
    "# Convert the timestamps to datetime objects\n",
    "train_data_timestamps = []\n",
    "for ts_list in train_timestamps:\n",
    "    ts_list = [int(datetime.strptime(ts, '%Y-%m-%d %H:%M:%S').timestamp()) for ts in ts_list]\n",
    "    train_data_timestamps.append(ts_list)\n",
    "\n",
    "val_data_timestamps = []\n",
    "for ts_list in val_timestamps:\n",
    "    ts_list = [int(datetime.strptime(ts, '%Y-%m-%d %H:%M:%S').timestamp()) for ts in ts_list]\n",
    "    val_data_timestamps.append(ts_list)\n",
    "\n",
    "test_data_timestamps = []\n",
    "for ts_list in test_timestamps:\n",
    "    ts_list = [int(datetime.strptime(ts, '%Y-%m-%d %H:%M:%S').timestamp()) for ts in ts_list]\n",
    "    test_data_timestamps.append(ts_list)\n",
    "\n",
    "train_timestamps_padded = tf.keras.preprocessing.sequence.pad_sequences(train_data_timestamps, padding='post', maxlen=MAX_SEQ_LENGTH)\n",
    "val_timestamps_padded = tf.keras.preprocessing.sequence.pad_sequences(val_data_timestamps, padding='post', maxlen=MAX_SEQ_LENGTH)\n",
    "test_timestamps_padded = tf.keras.preprocessing.sequence.pad_sequences(test_data_timestamps, padding='post', maxlen=MAX_SEQ_LENGTH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "3b0543dd-4b22-4993-b1a4-8f59342dac29",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQ_LENGTH = 1265\n",
    "# normalizing time inputs was super important!!\n",
    "max_time = 1./np.max(train_timestamps_padded)\n",
    "train_timestamps_padded = (train_timestamps_padded*max_time).astype(np.float32)\n",
    "val_timestamps_padded = (val_timestamps_padded*max_time).astype(np.float32)\n",
    "test_timestamps_padded = (test_timestamps_padded*max_time).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "90e9ec27-109c-4d61-a5bc-ee1e9c4379f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the time decay function\n",
    "def time_decay(epoch):\n",
    "    lrate = INIT_LR * pow(DECAY_FACTOR, np.floor((1+epoch)/DECAY_EPOCHS))\n",
    "    return lrate\n",
    "\n",
    "# Define the input layers\n",
    "EmbeddingInput = Input(shape=(MAX_SEQ_LENGTH,512), name='embeddings')\n",
    "TimeInput = Input(shape=(MAX_SEQ_LENGTH,), name='times')\n",
    "\n",
    "decay_layer = Lambda(lambda t: tf.math.exp(-(t - tf.roll(t, shift=1, axis=1)) / 86400), name='decay_layer')(TimeInput)\n",
    "\n",
    "decay_layer_2 = tf.expand_dims(decay_layer, axis=-1, name='decay_layer_2')\n",
    "\n",
    "gru_layer = GRU(GRU_HIDDEN_DIM, dropout=DROPOUT_RATE, return_sequences=True, name='gru')(EmbeddingInput, mask=EmbeddingInput._keras_mask)\n",
    "multiply = tf.keras.layers.Multiply(name='multiply')([gru_layer, decay_layer_2])\n",
    "flatten_layer = tf.keras.layers.Flatten(name='flatten')(multiply)\n",
    "outputs = Dense(NUM_CLASSES, activation='softmax')(flatten_layer)\n",
    "\n",
    "model = Model(inputs=[EmbeddingInput, TimeInput], outputs=outputs)\n",
    "\n",
    "optimizer = Adam(learning_rate=INIT_LR)\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "86b1ab86-dedf-45ed-a20a-4b9fa381175d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " times (InputLayer)             [(None, 1265)]       0           []                               \n",
      "                                                                                                  \n",
      " embeddings (InputLayer)        [(None, 1265, 512)]  0           []                               \n",
      "                                                                                                  \n",
      " decay_layer (Lambda)           (None, 1265)         0           ['times[0][0]']                  \n",
      "                                                                                                  \n",
      " gru (GRU)                      (None, 1265, 256)    591360      ['embeddings[0][0]']             \n",
      "                                                                                                  \n",
      " tf.expand_dims_2 (TFOpLambda)  (None, 1265, 1)      0           ['decay_layer[0][0]']            \n",
      "                                                                                                  \n",
      " multiply (Multiply)            (None, 1265, 256)    0           ['gru[0][0]',                    \n",
      "                                                                  'tf.expand_dims_2[0][0]']       \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 323840)       0           ['multiply[0][0]']               \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 2)            647682      ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,239,042\n",
      "Trainable params: 1,239,042\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e1e5c3d6-89c7-4bef-ab74-0ad7ed7a1429",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "13/13 [==============================] - 32s 2s/step - loss: 0.4914 - accuracy: 0.7551 - val_loss: 0.3016 - val_accuracy: 0.8980 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "13/13 [==============================] - 22s 2s/step - loss: 0.1872 - accuracy: 0.9362 - val_loss: 0.2058 - val_accuracy: 0.9184 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "13/13 [==============================] - 22s 2s/step - loss: 0.1125 - accuracy: 0.9617 - val_loss: 0.2898 - val_accuracy: 0.8980 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "13/13 [==============================] - 22s 2s/step - loss: 0.0768 - accuracy: 0.9847 - val_loss: 0.1658 - val_accuracy: 0.9184 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "13/13 [==============================] - 22s 2s/step - loss: 0.0532 - accuracy: 0.9796 - val_loss: 0.2102 - val_accuracy: 0.9388 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "13/13 [==============================] - 22s 2s/step - loss: 0.0571 - accuracy: 0.9872 - val_loss: 0.2597 - val_accuracy: 0.8980 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "13/13 [==============================] - 22s 2s/step - loss: 0.0345 - accuracy: 0.9949 - val_loss: 0.2371 - val_accuracy: 0.8980 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "13/13 [==============================] - 22s 2s/step - loss: 3.0798 - accuracy: 0.9694 - val_loss: 1.9471 - val_accuracy: 0.8776 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "13/13 [==============================] - 22s 2s/step - loss: 0.4925 - accuracy: 0.8750 - val_loss: 0.3483 - val_accuracy: 0.9184 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "13/13 [==============================] - 22s 2s/step - loss: 0.1136 - accuracy: 0.9566 - val_loss: 0.2564 - val_accuracy: 0.8980 - lr: 1.0000e-04\n"
     ]
    }
   ],
   "source": [
    "lr_scheduler = LearningRateScheduler(time_decay)\n",
    "\n",
    "history = model.fit([train_data, train_timestamps_padded], train_labels, validation_data=([val_data, val_timestamps_padded], val_labels), epochs=10, batch_size=32, callbacks=[lr_scheduler])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b04c43b1-8622-49dd-9d07-00c13793930c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 1s 537ms/step - loss: 0.1814 - accuracy: 0.9184\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.18137145042419434, 0.918367326259613]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate([test_data, test_timestamps_padded], test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "3906749d-2352-466a-9860-b8a56a57a126",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 2s 475ms/step\n",
      "Test F1 Score: 0.9180602006688963\n",
      "Test AUROC: 0.9175\n",
      "Test AUPRC: 0.8737414965986394\n",
      "Test Accuracy: 0.9183673469387755\n",
      "Test Recall: 0.9175\n",
      "Test Precision: 0.9217171717171717\n",
      "Test F1 Score: 0.9180602006688963\n"
     ]
    }
   ],
   "source": [
    "test_preds = model.predict([test_data, test_timestamps_padded])\n",
    "test_preds = np.argmax(test_preds, axis=1)\n",
    "test_f1_score = f1_score(np.argmax(test_labels, axis=1), test_preds, average='macro')\n",
    "print('Test F1 Score:', test_f1_score)\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, accuracy_score, recall_score, precision_score\n",
    "# Calculate AUROC\n",
    "test_auroc = roc_auc_score(np.argmax(test_labels, axis=1), test_preds)\n",
    "# Calculate AUPRC\n",
    "test_auprc = average_precision_score(np.argmax(test_labels, axis=1), test_preds)\n",
    "# Calculate accuracy\n",
    "test_accuracy = accuracy_score(np.argmax(test_labels, axis=1), test_preds)\n",
    "# Calculate recall\n",
    "test_recall = recall_score(np.argmax(test_labels, axis=1), test_preds, average='macro')\n",
    "# Calculate precision\n",
    "test_precision = precision_score(np.argmax(test_labels, axis=1), test_preds, average='macro')\n",
    "\n",
    "print('Test AUROC:', test_auroc)\n",
    "print('Test AUPRC:', test_auprc)\n",
    "print('Test Accuracy:', test_accuracy)\n",
    "print('Test Recall:', test_recall)\n",
    "print('Test Precision:', test_precision)\n",
    "print('Test F1 Score:', test_f1_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593b376a-3f14-40a7-b1b6-22a6f0682b87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56e5b4c-9dcf-498b-aa52-b2a3ad093027",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
